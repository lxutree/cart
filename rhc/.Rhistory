} else {
# calculating sse for binary feature:
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
}
} else {
# calculating sse for continuous feature:
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 2:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
}
# clean up for when none of the splits is valid:
error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]
}
}
if(all(is.na(error))){
# if none of the splits is good, consider the current node to 'leaf'
output$status[j] = "leaf"
} else { # else keep going
# characteristics of the current split
splitvar = feat[which.min(error)] # feature leading to the lowest sse
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = levels(data.temp[[splitvar]])[!(levels(data.temp[[splitvar]]) %in% yeslevels)]
data.next = list()
data.next[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
data.next[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else {
# for binary feature
data.next = split(data.temp, data.temp[ , splitvar])
}
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
data.next = list()
data.next[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
data.next[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
status = sapply(data.next, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "=", paste(nolevels, collapse = ",")), paste(splitvar, "=", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(data.next), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(data.next, nrow), "split rule" = splitrule, iter = output$iter[j] + 1, row.names = NULL, mean = sapply(data.next, function(x){mean(x[[resp]])}))
# attach new outputs to existing dataframe
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(data.next) = NULL; data.list = c(data.list[1:j], data.next, data.list[-c(1:j)])
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
}
}
output
data.list = list(); data.list[[1]] = data
stopsplit=FALSE # boolean for the while loop
min.obs = 1000
feat = c("Albumin", "Cardiovascular", "Disease.category")
while(!stopsplit) { # while loop will keep going as long as stopsplit is 'FALSE'
# list of splits to be done:
split.queue = which(output$status == "split")
for (j in split.queue[1]) {
# empty objects for later use
error = c()
split_val = list()
# load data corresponding to current node
data.temp = data.list[[j]]
for (i in 1:length(feat)){ # loop through all features
data_sub = data.frame(var = data.temp[, feat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if( is.factor(data_sub$var) ) {
if( length(levels(data_sub$var)) > 2 ){
# find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# record optimal split
error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]
} else {
# calculating sse for binary feature:
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
}
} else {
# calculating sse for continuous feature:
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 2:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
}
# clean up for when none of the splits is valid:
error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]
}
}
if(all(is.na(error))){
# if none of the splits is good, consider the current node to 'leaf'
output$status[j] = "leaf"
} else { # else keep going
# characteristics of the current split
splitvar = feat[which.min(error)] # feature leading to the lowest sse
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = levels(data.temp[[splitvar]])[!(levels(data.temp[[splitvar]]) %in% yeslevels)]
data.next = list()
data.next[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
data.next[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else {
# for binary feature
data.next = split(data.temp, data.temp[ , splitvar])
}
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
data.next = list()
data.next[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
data.next[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
status = sapply(data.next, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "=", paste(nolevels, collapse = ",")), paste(splitvar, "=", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(data.next), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(data.next, nrow), "split rule" = splitrule, iter = output$iter[j] + 1, row.names = NULL, mean = sapply(data.next, function(x){mean(x[[resp]])}))
# attach new outputs to existing dataframe
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(data.next) = NULL; data.list = c(data.list[1:j], data.next, data.list[-c(1:j)])
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
}
}
output
min.obs
min.obs
data.list = list(); data.list[[1]] = data
stopsplit=FALSE # boolean for the while loop
min.obs = 1000
feat = c("Albumin", "Cardiovascular", "Disease.category")
# list of splits to be done:
split.queue = which(output$status == "split")
for (j in split.queue[1]) {
# empty objects for later use
error = c()
split_val = list()
# load data corresponding to current node
data.temp = data.list[[j]]
for (i in 1:length(feat)){ # loop through all features
data_sub = data.frame(var = data.temp[, feat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if( is.factor(data_sub$var) ) {
if( length(levels(data_sub$var)) > 2 ){
# find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# record optimal split
error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]
} else {
# calculating sse for binary feature:
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
}
} else {
# calculating sse for continuous feature:
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 2:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
}
# clean up for when none of the splits is valid:
error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]
}
}
if(all(is.na(error))){
# if none of the splits is good, consider the current node to 'leaf'
output$status[j] = "leaf"
} else { # else keep going
# characteristics of the current split
splitvar = feat[which.min(error)] # feature leading to the lowest sse
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = levels(data.temp[[splitvar]])[!(levels(data.temp[[splitvar]]) %in% yeslevels)]
data.next = list()
data.next[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
data.next[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else {
# for binary feature
data.next = split(data.temp, data.temp[ , splitvar])
}
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
data.next = list()
data.next[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
data.next[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
status = sapply(data.next, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "=", paste(nolevels, collapse = ",")), paste(splitvar, "=", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(data.next), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(data.next, nrow), "split rule" = splitrule, iter = output$iter[j] + 1, row.names = NULL, mean = sapply(data.next, function(x){mean(x[[resp]])}))
# attach new outputs to existing dataframe
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(data.next) = NULL; data.list = c(data.list[1:j], data.next, data.list[-c(1:j)])
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
}
for (j in split.queue[1]) {
# empty objects for later use
error = c()
split_val = list()
# load data corresponding to current node
data.temp = data.list[[j]]
for (i in 1:length(feat)){ # loop through all features
data_sub = data.frame(var = data.temp[, feat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if( is.factor(data_sub$var) ) {
if( length(levels(data_sub$var)) > 2 ){
# find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# record optimal split
error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]
} else {
# calculating sse for binary feature:
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
}
} else {
# calculating sse for continuous feature:
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 2:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
}
# clean up for when none of the splits is valid:
error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]
}
}
if(all(is.na(error))){
# if none of the splits is good, consider the current node to 'leaf'
output$status[j] = "leaf"
} else { # else keep going
# characteristics of the current split
splitvar = feat[which.min(error)] # feature leading to the lowest sse
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = levels(data.temp[[splitvar]])[!(levels(data.temp[[splitvar]]) %in% yeslevels)]
data.next = list()
data.next[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
data.next[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else {
# for binary feature
data.next = split(data.temp, data.temp[ , splitvar])
}
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
data.next = list()
data.next[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
data.next[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
status = sapply(data.next, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "=", paste(nolevels, collapse = ",")), paste(splitvar, "=", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(data.next), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(data.next, nrow), "split rule" = splitrule, iter = output$iter[j] + 1, row.names = NULL, mean = sapply(data.next, function(x){mean(x[[resp]])}))
# attach new outputs to existing dataframe
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(data.next) = NULL; data.list = c(data.list[1:j], data.next, data.list[-c(1:j)])
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
}
warnings()
j
split.queue
output = data.frame(status = "split", count = nrow(data), "split rule" = "root", iter = 0, mean = mean(data[, resp]), stringsAsFactors = FALSE)
while(!stopsplit) { # while loop will keep going as long as stopsplit is 'FALSE'
# list of splits to be done:
split.queue = which(output$status == "split")
for (j in split.queue[1]) {
# empty objects for later use
error = c()
split_val = list()
# load data corresponding to current node
data.temp = data.list[[j]]
for (i in 1:length(feat)){ # loop through all features
data_sub = data.frame(var = data.temp[, feat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if( is.factor(data_sub$var) ) {
if( length(levels(data_sub$var)) > 2 ){
# find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# record optimal split
error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]
} else {
# calculating sse for binary feature:
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
}
} else {
# calculating sse for continuous feature:
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 2:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
}
# clean up for when none of the splits is valid:
error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]
}
}
if(all(is.na(error))){
# if none of the splits is good, consider the current node to 'leaf'
output$status[j] = "leaf"
} else { # else keep going
# characteristics of the current split
splitvar = feat[which.min(error)] # feature leading to the lowest sse
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = levels(data.temp[[splitvar]])[!(levels(data.temp[[splitvar]]) %in% yeslevels)]
data.next = list()
data.next[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
data.next[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else {
# for binary feature
data.next = split(data.temp, data.temp[ , splitvar])
}
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
data.next = list()
data.next[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
data.next[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
status = sapply(data.next, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "=", paste(nolevels, collapse = ",")), paste(splitvar, "=", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(data.next), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(data.next, nrow), "split rule" = splitrule, iter = output$iter[j] + 1, row.names = NULL, mean = sapply(data.next, function(x){mean(x[[resp]])}))
# attach new outputs to existing dataframe
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(data.next) = NULL; data.list = c(data.list[1:j], data.next, data.list[-c(1:j)])
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
}
}
output
library(rparrt)
library(rparr)
library(rpar)
library(rpart)
rpart(Y ~ Cardiovascular + Albumin + Disease.category, data = data, minsplit = 4000, minbucket = 4000)
rpart(Y ~ Cardiovascular + Albumin + Disease.category, data = data, minsplit = 4000, minbucket = 2000)
rpart(Y ~ Cardiovascular + Albumin + Disease.category, data = data, minsplit = 4000)
rpart(Y ~ Cardiovascular + Albumin + Disease.category, data = data, minsplit = 4000, minbucket = 2)
rpart(Y ~ Cardiovascular + Albumin + Disease.category, data = data, minsplit = 4000, minbucket = 2,  cp=-1)
rpart(Y ~ Cardiovascular + Albumin + Disease.category, data = data, minsplit = 4000,  cp=-1)
