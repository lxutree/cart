# load data corresponding to current node
data.temp = data.list[[j]]
### additional condition for random forest
if(!is.null(nfeat)) subfeat = sample(feat, nfeat, replace = FALSE) else subfeat = feat
# For each feature of interest, determine the optimal split
for (i in 1:length(subfeat)){
data_sub = data.frame(var = data.temp[, subfeat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if(is.factor(data_sub$var)) {
if( length(levels(data_sub$var)) > 2 ){
# if more than 2 levels find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = sapply(varcomb, function(varcomb_i){min(length(data_sub$resp[data_sub$var %in% varcomb_i]), length(data_sub$resp[!(data_sub$var %in% varcomb_i)]))})
for(ii in 1:length(varcomb)) {if(count_min[ii] < round(leafsize)) sse[ii] = NA}
# clean up:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]}
} else {
# if only two levels
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = min(sapply(data.split, nrow))
if( count_min < leafsize) error[i] = NA
}
# calculating sse for continuous feature:
} else {
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 1:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
# checking size of children nodes; if less than specified, the split is not considered
count_min = min(length(data_sub$resp[data_sub$var < splits_sort[k]]), length(data_sub$resp[data_sub$var >= splits_sort[k]]))
if(count_min < round(leafsize)) sse[k] = NA
}
# clean up for when none of the splits is valid:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]}
}
}
if(all(is.na(error))){
# if none of the splits is good, set the current node to 'leaf'
output$status[j] = "leaf"
} else {
# otherwise proceed with the split and choose the feature leading to the lowest sse
splitvar = subfeat[which.min(error)]
feat_list[[iter]] = subfeat # to record variables considered for each split
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = unique(data.temp[[splitvar]])[!(unique(data.temp[[splitvar]]) %in% yeslevels)]
children = list()
children[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
children[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else children = split(data.temp, data.temp[ , splitvar])
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
children = list()
children[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
children[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
# - less than 3 observations
# - all observations have the same label
status = sapply(children, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "in", paste(nolevels, collapse = ",")), paste(splitvar, "in", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(children), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(children, nrow), "split rule" = splitrule, depth = output$depth[j] + 1, row.names = NULL, mean = sapply(children, function(x){mean(x[,resp])}))
# record observations in each node:
node.ID = c(node.ID[1:j], lapply(data.next, function(x){row.names(x)}), node.ID[-c(1:j)])
# attach new outputs to existing dataframes
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(children) = NULL; data.list = c(data.list[1:j], children, data.list[-c(1:j)])
iter = iter+1
}
}
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
return(list(output = output, feat_list = feat_list))
}
tree = regtree(data = data.frame(drdata2[,c("race", "gender")], resid = resid), min.obs = 500, resp = "resid")
regtree <- function(data, resp, min.obs, feat = NULL, nfeat = NULL){
# min.obs sets the minimum size for parent nodes
# feat is the set of predictors
if(is.null(feat)) feat = names(data)[names(data)!=resp] # if undefined, set feat to all covariates in the data
leafsize = min.obs/3 # set minimum size for leaves or terminal nodes
data.list = split_val = feat_list = list(); error = c() # empty objects
data.list[[1]] = data # set root of tree
# id of observations pertaning to each node
node.ID = list(100)
# data.frame to store output:
output = data.frame(status = "split", count = nrow(data), "split rule" = "root", depth = 0, mean = mean(data[, resp]), stringsAsFactors = FALSE)
stopsplit = FALSE; iter = 1 # initialization for while loop
while(!stopsplit) {
# list of splits to be done:
split.queue = which(output$status == "split")
for (j in split.queue[1]) {
# load data corresponding to current node
data.temp = data.list[[j]]
### additional condition for random forest
if(!is.null(nfeat)) subfeat = sample(feat, nfeat, replace = FALSE) else subfeat = feat
# For each feature of interest, determine the optimal split
for (i in 1:length(subfeat)){
data_sub = data.frame(var = data.temp[, subfeat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if(is.factor(data_sub$var)) {
if( length(levels(data_sub$var)) > 2 ){
# if more than 2 levels find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = sapply(varcomb, function(varcomb_i){min(length(data_sub$resp[data_sub$var %in% varcomb_i]), length(data_sub$resp[!(data_sub$var %in% varcomb_i)]))})
for(ii in 1:length(varcomb)) {if(count_min[ii] < round(leafsize)) sse[ii] = NA}
# clean up:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]}
} else {
# if only two levels
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = min(sapply(data.split, nrow))
if( count_min < leafsize) error[i] = NA
}
# calculating sse for continuous feature:
} else {
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 1:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
# checking size of children nodes; if less than specified, the split is not considered
count_min = min(length(data_sub$resp[data_sub$var < splits_sort[k]]), length(data_sub$resp[data_sub$var >= splits_sort[k]]))
if(count_min < round(leafsize)) sse[k] = NA
}
# clean up for when none of the splits is valid:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]}
}
}
if(all(is.na(error))){
# if none of the splits is good, set the current node to 'leaf'
output$status[j] = "leaf"
} else {
# otherwise proceed with the split and choose the feature leading to the lowest sse
splitvar = subfeat[which.min(error)]
feat_list[[iter]] = subfeat # to record variables considered for each split
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = unique(data.temp[[splitvar]])[!(unique(data.temp[[splitvar]]) %in% yeslevels)]
children = list()
children[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
children[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else children = split(data.temp, data.temp[ , splitvar])
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
children = list()
children[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
children[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
# - less than 3 observations
# - all observations have the same label
status = sapply(children, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "in", paste(nolevels, collapse = ",")), paste(splitvar, "in", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(children), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(children, nrow), "split rule" = splitrule, depth = output$depth[j] + 1, row.names = NULL, mean = sapply(children, function(x){mean(x[,resp])}))
# record observations in each node:
node.ID = c(node.ID[1:j], lapply(children, function(x){row.names(x)}), node.ID[-c(1:j)])
# attach new outputs to existing dataframes
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(children) = NULL; data.list = c(data.list[1:j], children, data.list[-c(1:j)])
iter = iter+1
}
}
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
return(list(output = output, feat_list = feat_list))
}
tree = regtree(data = data.frame(drdata2[,c("race", "gender")], resid = resid), min.obs = 500, resp = "resid")
tree
regtree <- function(data, resp, min.obs, feat = NULL, nfeat = NULL){
# min.obs sets the minimum size for parent nodes
# feat is the set of predictors
if(is.null(feat)) feat = names(data)[names(data)!=resp] # if undefined, set feat to all covariates in the data
leafsize = min.obs/3 # set minimum size for leaves or terminal nodes
data.list = split_val = feat_list = list(); error = c() # empty objects
data.list[[1]] = data # set root of tree
# id of observations pertaning to each node
node.ID = list(100)
# data.frame to store output:
output = data.frame(status = "split", count = nrow(data), "split rule" = "root", depth = 0, mean = mean(data[, resp]), stringsAsFactors = FALSE)
stopsplit = FALSE; iter = 1 # initialization for while loop
while(!stopsplit) {
# list of splits to be done:
split.queue = which(output$status == "split")
for (j in split.queue[1]) {
# load data corresponding to current node
data.temp = data.list[[j]]
### additional condition for random forest
if(!is.null(nfeat)) subfeat = sample(feat, nfeat, replace = FALSE) else subfeat = feat
# For each feature of interest, determine the optimal split
for (i in 1:length(subfeat)){
data_sub = data.frame(var = data.temp[, subfeat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if(is.factor(data_sub$var)) {
if( length(levels(data_sub$var)) > 2 ){
# if more than 2 levels find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = sapply(varcomb, function(varcomb_i){min(length(data_sub$resp[data_sub$var %in% varcomb_i]), length(data_sub$resp[!(data_sub$var %in% varcomb_i)]))})
for(ii in 1:length(varcomb)) {if(count_min[ii] < round(leafsize)) sse[ii] = NA}
# clean up:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]}
} else {
# if only two levels
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = min(sapply(data.split, nrow))
if( count_min < leafsize) error[i] = NA
}
# calculating sse for continuous feature:
} else {
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 1:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
# checking size of children nodes; if less than specified, the split is not considered
count_min = min(length(data_sub$resp[data_sub$var < splits_sort[k]]), length(data_sub$resp[data_sub$var >= splits_sort[k]]))
if(count_min < round(leafsize)) sse[k] = NA
}
# clean up for when none of the splits is valid:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]}
}
}
if(all(is.na(error))){
# if none of the splits is good, set the current node to 'leaf'
output$status[j] = "leaf"
} else {
# otherwise proceed with the split and choose the feature leading to the lowest sse
splitvar = subfeat[which.min(error)]
feat_list[[iter]] = subfeat # to record variables considered for each split
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = unique(data.temp[[splitvar]])[!(unique(data.temp[[splitvar]]) %in% yeslevels)]
children = list()
children[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
children[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else children = split(data.temp, data.temp[ , splitvar])
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
children = list()
children[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
children[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
# - less than 3 observations
# - all observations have the same label
status = sapply(children, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "in", paste(nolevels, collapse = ",")), paste(splitvar, "in", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(children), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(children, nrow), "split rule" = splitrule, depth = output$depth[j] + 1, row.names = NULL, mean = sapply(children, function(x){mean(x[,resp])}))
# record observations in each node:
node.ID = c(node.ID[1:j], lapply(children, function(x){row.names(x)}), node.ID[-c(1:j)])
# attach new outputs to existing dataframes
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(children) = NULL; data.list = c(data.list[1:j], children, data.list[-c(1:j)])
iter = iter+1
}
}
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
return(list(output = output, feat_list = feat_list, node.ID=node.ID))
}
tree = regtree(data = data.frame(drdata2[,c("race", "gender")], resid = resid), min.obs = 500, resp = "resid")
tree
tree = regtree(data = data.frame(drdata2[,feat], resid = resid), min.obs = 500, resp = "resid")
Kyphosis
library(Kyphosis )
library(rpart)
kyphosis
kyphosis$Kyphosis = ifelse(kyphosis$Kyphosis=="absent", 0, 1)
feat = names(kyphosis)[names(kyphosis)!=resp] # define covariates
feat
resp = "Kyphosis" # define response
feat = names(kyphosis)[names(kyphosis)!=resp] # define covariates
feat
table(kyphosis$Kyphosis)
logodds = as.numeric(log(table(kyphosis$Kyphosis)[2]/table(kyphosis$Kyphosis)[1]))
logodds
pred = rep(1/(1+exp(-(logodds))), nrow(drdata2), )
pred = rep(1/(1+exp(-(logodds))), nrow(kyphosis), )
pred
resid = kyphosis[, resp] - pred
kyphosis
resid
tree = regtree(data = data.frame(kyphosis[,feat], resid = resid), min.obs = 20, resp = "resid")
tree
j
j-1
j=2
tree$output[j, "mean"] * length(tree$node.ID)
sum(pred[as.numeric(tree$node.ID[[j]])]*(1 - pred[as.numeric(tree$node.ID[[j]])]))
tree$output$mean = c(NA, sapply(2:length(tree$node.ID), FUN = function(j){
tree$output[j, "mean"] * length(tree$node.ID) / sum(pred[as.numeric(tree$node.ID[[j]])]*(1 - pred[as.numeric(tree$node.ID[[j]])]))
}))
tree$output$mean
pred_resid = predtree(newdata = data, resp = resp, res = tree$output, data = data)[,resp]
source("helperfunctions.R")
pred_resid = predtree(newdata = data, resp = resp, res = tree$output, data = data)[,resp]
pred_resid = predtree(newdata = kyphosis, resp = resp, res = tree$output, data = kyphosis)[,resp]
tree$output
resp
kyphosis
predtree(newdata = kyphosis, resp = resp, res = tree$output, data = kyphosis)
tree$output
newdata = kyphosis
data = kyphosis
res = tree$output
# splitting rules from tree:
rules = data.frame(t(sapply(res$split.rule[-1 ], function(x){scan(text = x, what = "" , quiet = TRUE, )}, USE.NAMES = FALSE)), res$iter[-1], stringsAsFactors = FALSE)
sapply(res$split.rule[-1 ], function(x){scan(text = x, what = "" , quiet = TRUE, )}, USE.NAMES = FALSE)
res$iter
tree$output
# splitting rules from tree:
rules = data.frame(t(sapply(res$split.rule[-1 ], function(x){scan(text = x, what = "" , quiet = TRUE, )}, USE.NAMES = FALSE)), res[,4][-1], stringsAsFactors = FALSE)
rules
# function to generate predictions based on given tree
predtree = function(newdata, resp, res, data){
# splitting rules from tree:
rules = data.frame(t(sapply(res$split.rule[-1 ], function(x){scan(text = x, what = "" , quiet = TRUE, )}, USE.NAMES = FALSE)), res[,4][-1], stringsAsFactors = FALSE)
names(rules) = c("feat", "operator", "value", "iter")
for(k in 1:nrow(newdata)){
ii=1
stoploop = FALSE
while(!stoploop){
if(compare(newdata[k, rules[ii, "feat"]], rules[ii, "value"],  (rules[ii, "operator"]))) {
if(rules$iter[ii+1] == rules$iter[ii]) stoploop = TRUE else ii = ii + 1
} else {
ii = which(rules$feat == rules$feat[ii] & rules$iter == rules$iter[ii])[which(rules$feat == rules$feat[ii] & rules$iter == rules$iter[ii]) > ii][1]
}
if(rules$iter[ii+1] < rules$iter[ii] | ii == nrow(rules)) stoploop = TRUE
}
if(class(data[, resp]) == "factor"){
newdata[,resp][k] = if(res$prob[ii+1] > 0.5) levels(data[, resp])[1] else { if(res$prob[ii+1] == 0.5) levels(data[, resp])[sample(x = 2, size = 1, prob = c(0.5, 0.5))] else levels(data[, resp])[2]}
} else {
newdata[,resp][k] = res$mean[ii+1]
}
}
return(newdata)
}
pred_resid = predtree(newdata = kyphosis, resp = resp, res = tree$output, data = kyphosis)[,resp]
pred_resid
logodds = logodds + pred_resid*rate
rate = 0.1
logodds = logodds + pred_resid*rate
pred_list = 1/(1+exp(-(logodds)))
pred_list
pred = 1/(1+exp(-(logodds)))
pred
resid = kyphosis[, resp] - pred
tree$output$mean
library(pROC)
auc(pred, kyphosis$Kyphosis)
pred
auc(pred, kyphosis$Kyphosis)
?auc()
?auc
?auc()
?sum()
?rpart
roc(pred, kyphosis$Kyphosis)
roc(kyphosis$Kyphosis, pred)
tree = regtree(data = data.frame(kyphosis[,feat], resid = resid), min.obs = 20, resp = "resid")
tree$output$mean = c(NA, sapply(2:length(tree$node.ID), FUN = function(j){
tree$output[j, "mean"] * length(tree$node.ID) / sum(pred[as.numeric(tree$node.ID[[j]])]*(1 - pred[as.numeric(tree$node.ID[[j]])]))
}))
pred_resid = predtree(newdata = kyphosis, resp = resp, res = tree$output, data = kyphosis)[,resp]
logodds = logodds + pred_resid*rate
pred = 1/(1+exp(-(logodds)))
resid = kyphosis[, resp] - pred
roc(kyphosis$Kyphosis, pred)
tree = regtree(data = data.frame(kyphosis[,feat], resid = resid), min.obs = 20, resp = "resid")
tree$output$mean = c(NA, sapply(2:length(tree$node.ID), FUN = function(j){
tree$output[j, "mean"] * length(tree$node.ID) / sum(pred[as.numeric(tree$node.ID[[j]])]*(1 - pred[as.numeric(tree$node.ID[[j]])]))
}))
pred_resid = predtree(newdata = kyphosis, resp = resp, res = tree$output, data = kyphosis)[,resp]
logodds = logodds + pred_resid*rate
pred = 1/(1+exp(-(logodds)))
resid = kyphosis[, resp] - pred
roc(kyphosis$Kyphosis, pred)
for (i in 4:100){
tree = regtree(data = data.frame(kyphosis[,feat], resid = resid), min.obs = 20, resp = "resid")
tree$output$mean = c(NA, sapply(2:length(tree$node.ID), FUN = function(j){
tree$output[j, "mean"] * length(tree$node.ID) / sum(pred[as.numeric(tree$node.ID[[j]])]*(1 - pred[as.numeric(tree$node.ID[[j]])]))
}))
pred_resid = predtree(newdata = kyphosis, resp = resp, res = tree$output, data = kyphosis)[,resp]
logodds = logodds + pred_resid*rate
pred = 1/(1+exp(-(logodds)))
resid = kyphosis[, resp] - pred
}
roc(kyphosis$Kyphosis, pred)
pred
library(h2o)
h2o.init(nthreads = -1)
h2o.init(nthreads = -1)
?h20.init
??h20.init
?h2o.init
