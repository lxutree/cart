---
title: "Diabetes"
author: "Liang"
date: "26/10/2021"
output: html_document
---

This document aims to present the general steps for analyzing binary data. Data will be processed and analyzed as in Strack B. et al. [1].

### 1. Data Inspection
```{r, echo=FALSE}
# working directory
setwd("~/../LX_Project/cart/diabetes/")

library(stringr)
library(ggplot2)
library(rpart) 
library(gbm)
library(pROC)
library(caret)
library(rms)
library(rpart)
library(ipred)
library(xgboost)
library(mltools)
library(data.table)

source("../class.R") # load cart function

## read data:
data = read.csv(file = "diabetic_data.csv", stringsAsFactors = TRUE)

## exclusions
# 1. only keep first obs from the same patient (with the same unique_id)
unique_id = sapply(unique(data$patient_nbr), FUN = function(x){
  which(data$patient_nbr == x)[1]
})
data = data[unique_id, ]

# delete encounter_id now
data$encounter_id <- NULL

# 2. remove patients that entered hospice or passed away after discharge
data = data[ -which(data$discharge_disposition_id %in% c(11, 13, 14, 19, 20, 21)), ]

# check missing data:
apply(data, MARGIN = 2, FUN = function(x){length(which(x == "?"))})
# 'medical_specialty', 'weight' and 'payer_code' have lots of missing data

# remove the variables 'weight' and 'payer_code'
data$weight <- NULL
data$payer_code <- NULL

nrow(data)
# 69973, which is 11 less than the value reported (69984)
```

### Coding of predictors

The predictors are coded following the steps outlined in the paper.
```{r}
# re-coding some of the variables:
data$readmitted = as.factor(ifelse(data$readmitted == "<30", "YES", "NO"))

data$A1Cresult = as.factor(ifelse(data$A1Cresult %in% c("Norm", ">7"), "Normal", ifelse(data$A1Cresult == "None", "None", ifelse(data$change == "Ch", "high_ch", "high_noch"))))

data$discharge_disposition_id = as.factor(ifelse(data$discharge_disposition_id == 1, "Home", "Other"))

data$admission_source_id = as.factor(ifelse(data$admission_source_id == 7, "Emergency", ifelse(data$admission_source_id %in% c(1,2), "Referral", "Other")))

data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Cardiology-Pediatric", "Cardiology")

data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgeon", "SurgicalSpecialty")

data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgery-Cardiovascular/Thoracic", "SurgicalSpecialty")
data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgery-Colon&Rectal", "SurgicalSpecialty")
data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgery-General", "SurgicalSpecialty")
data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgery-Maxillofacial", "SurgicalSpecialty")
data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgery-Neuro", "SurgicalSpecialty")
data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgery-Pediatric", "SurgicalSpecialty")
data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgery-Plastic", "SurgicalSpecialty")
data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgery-PlasticwithinHeadandNeck", "SurgicalSpecialty")
data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgery-Thoracic", "SurgicalSpecialty")
data$medical_specialty <- replace(data$medical_specialty, data$medical_specialty == "Surgery-Vascular", "SurgicalSpecialty")
data$medical_specialty <- str_replace(data$medical_specialty, "SurgicalSpecialty", "Surgery")
data$medical_specialty[which(data$medical_specialty == "?")] = "Missing or Unknown" 
data$medical_specialty[which(!(data$medical_specialty %in% c("InternalMedicine", "Cardiology", "Surgery", "Family/GeneralPractice", "Missing or Unknown")))] = "Other" 
diag_diabetes = levels(data$diag_1)[which(substr(levels(data$diag_1), 1, 3)==250)]
diag_other = levels(data$diag_1)[which(!(levels(data$diag_1) %in% c(390:459, 785, diag_diabetes, 460:519, 786, 520:579, 787, 800:999, 710:739, 580:629, 788, 140:239)))]
levels(data$diag_1) <- list(
  "Circulatory" = c(390:459, 785), 
  "Diabetes" = diag_diabetes, 
  "Respiratory" = c(460:519, 786), 
  "Digestive" = c(520:579, 787),
  "Injury and poisoning" = c(800:999),
  "Musculoskeletal" = c(710:739),
  "Genitourinary" = c(580:629, 788),
  "Neoplasms" = c(140:239),
  "Other" = diag_other
  )

levels(data$race) = list("Missing" = "?", "Other" = c("Other", "Asian", "Hispanic"), "African American" = "AfricanAmerican", "Caucasian" = "Caucasian" )

data$age_num = data$age
levels(data$age_num) = list("5" = "[0-10)", "15" = "[10-20)", "25" = "[20-30)", "35" = "[30-40)", "45" = "[40-50)", "55" = "[50-60)", "65" = "[60-70)", "75" = "[70-80)", "85" = "[80-90)", "95" = "[90-100)")

data$age_num = as.numeric(as.character(data$age_num))

levels(data$age) = list("< 30" = c("[0-10)", "[10-20)", "[20-30)" ), "[30, 60)" = c("[30-40)", "[40-50)", "[50-60)"), "[60, 100) " = c("[60-70)", "[70-80)", "[80-90)", "[90-100)"))

data$medical_specialty <- as.factor(data$medical_specialty)
data$medical_specialty <-droplevels(data$medical_specialty)

# change the baseline level for some factors:
data$race = relevel(data$race, ref = "African American")

data$age = relevel(data$age, ref = "[30, 60)") 

data$diag_1 = relevel(data$diag_1, ref = "Diabetes") 

data$A1Cresult =  relevel(data$A1Cresult, ref = "None") 

# tables:
HbA1c = as.data.frame(cbind("HbA1c", levels(data$A1Cresult), table(data$A1Cresult),  (table(data$A1Cresult))/nrow(data), table(data$A1Cresult, data$readmitted)[, 2], table(data$A1Cresult, data$readmitted)[, 2]/table(data$A1Cresult)))

gender = as.data.frame(cbind("gender", levels(data$gender), table(data$gender),  (table(data$gender))/nrow(data), table(data$gender, data$readmitted)[, 2], table(data$gender, data$readmitted)[, 2]/table(data$gender)))

discharge = as.data.frame(cbind("discharge", levels(data$discharge_disposition_id), table(data$discharge_disposition_id),  (table(data$discharge_disposition_id))/nrow(data), table(data$discharge_disposition_id, data$readmitted)[, 2], table(data$discharge_disposition_id, data$readmitted)[, 2]/table(data$discharge_disposition_id)))

admission = as.data.frame(cbind("admission", levels(data$admission_source_id), table(data$admission_source_id),  (table(data$admission_source_id))/nrow(data), table(data$admission_source_id, data$readmitted)[, 2], table(data$admission_source_id, data$readmitted)[, 2]/table(data$admission_source_id)))

specialty = as.data.frame(cbind("specialty", levels(data$medical_specialty), table(data$medical_specialty),  (table(data$medical_specialty))/nrow(data), table(data$medical_specialty, data$readmitted)[, 2], table(data$medical_specialty, data$readmitted)[, 2]/table(data$medical_specialty)))

diagnosis = as.data.frame(cbind("diagnosis", levels(data$diag_1), table(data$diag_1),  (table(data$diag_1))/nrow(data), table(data$diag_1, data$readmitted)[, 2], table(data$diag_1, data$readmitted)[, 2]/table(data$diag_1)))

race = as.data.frame(cbind("race", levels(data$race), table(data$race),  (table(data$race))/nrow(data), table(data$race, data$readmitted)[, 2], table(data$race, data$readmitted)[, 2]/table(data$race)))

age = as.data.frame(cbind("age", levels(data$age), table(data$age),  (table(data$age))/nrow(data), table(data$age, data$readmitted)[, 2], table(data$age, data$readmitted)[, 2]/table(data$age)))

names(data)[7] <- "source"
names(data)[6] <- "discharge"
summarytable = rbind(HbA1c, gender, discharge, admission, specialty, diagnosis, race, age)
names(summarytable) = c("Variable", "Level", "# of encounters", "% of population", "# of encounters (readmitted)", "% in group (readmitted)")
row.names(summarytable) = NULL
summarytable$`% of population` = as.numeric(as.character(summarytable$`% of population`))
summarytable$`% in group (readmitted)` = as.numeric(as.character(summarytable$`% in group (readmitted)`))
summarytable$`% of population` = round((summarytable$`% of population`)* 100, digits = 2)
summarytable$`% in group (readmitted)` = round((summarytable$`% in group (readmitted)`)* 100, digits = 2)
summarytable

# mean and quantiles for numeric variables age and time in hospital:
mean(data$age_num)
quantile(data$age_num, probs = c(0.5, 0.25, 0.75))

mean(data$time_in_hospital)
quantile(data$time_in_hospital, probs = c(0.5, 0.25, 0.75))
```

### Model specifiction

For the purpose of comparison, we select the same set of predictors and interactions as in the paper. 

### Model Estimation 

We fit a logistic regression with the full dataset at a significance level of 0.01. The results should be comparable to the values reported in Table 4.
```{r}
fit_full = glm(readmitted ~ discharge + race + source + medical_specialty + time_in_hospital + age + diag_1 + A1Cresult  +  diag_1 * discharge + race * discharge + medical_specialty*discharge + discharge*time_in_hospital + time_in_hospital*medical_specialty + age * medical_specialty + time_in_hospital*diag_1 + A1Cresult* diag_1, family = "binomial", data = data)

summary(fit_full)
```

### Model Performance

#### Pseudo $R^2$

For logistic regression, there are several measures of goodness of fit akin to $R^2$ in linear regression, including Brier score and Nagelkerke's $R^2$. Brier score is mean of the difference between the predicted probabilities and the actual outcome. Note that the Brier score is quite close to that for the null model, suggesting the model may not be very useful at explaining the variability in the data. 

```{r}
fitnull = glm(readmitted ~ 1, family = "binomial", data = data)
prednull <- predict(fitnull, data, type = "response")
brierScore_null <- mean((prednull - ifelse(data$readmitted == "NO", 0 , 1))^2)

fit = glm(readmitted ~ discharge + race + source + medical_specialty + time_in_hospital + age + diag_1 + A1Cresult  +  diag_1 * discharge + race * discharge + medical_specialty*discharge + discharge*time_in_hospital + time_in_hospital*medical_specialty + age * medical_specialty + time_in_hospital*diag_1 + A1Cresult* diag_1, family = "binomial", data = data)
pred <- predict(fit, data, type='response')
brierScore <- mean((pred - ifelse(data$readmitted == "NO", 0 , 1))^2)

print(c(brierScore, brierScore_null))
```

Compute Nagelkerke's $R^2$ with package 'rms':
```{r}
fit_rms = lrm(readmitted ~ discharge + race + source + medical_specialty + time_in_hospital + age + diag_1 + A1Cresult  +  diag_1 * discharge + race * discharge + medical_specialty*discharge + discharge*time_in_hospital + time_in_hospital*medical_specialty + age * medical_specialty + time_in_hospital*diag_1 + A1Cresult* diag_1, data = data)
fit_rms$stats["R2"]
```

#### Predictive performance

To assess the predictive performance of the logistic model, we can resort to measures such as accuracy, classification error, sensitivity and specificity.

First generate predictions using a desired cutoff point (0.15 in this case) and compare to the observed outcome:
```{r}
pred_outcome = as.factor(ifelse(pred<0.15, "NO", "YES"))
confmatrix = dummy = table(data$readmitted, pred_outcome,dnn = NULL)
confmatrix
```

The top left cell shows the number of true negatives, the top right cell shows the number of false negatives, the bottom left cell shows the number of false positives and the bottom right cell shows the number of true positives:
```{r}
dummy[1,1] = 'TN'
dummy[1,2] = 'FN'
dummy[2,1] = 'FP'
dummy[2,2] = 'TP'
dummy
```

Accuracy is the proportion of true positives and negatives. $Accuracy = \frac{TP + TN}{Total}$

```{r}
(61095+514) / (nrow(data))
```

Classification error is the proportion of false positives and negatives. $Classification error = \frac{FP + FN}{Total}$

```{r}
(5763+5763) / (nrow(data))
```

Sensitivity is proportion of patients with actual readmissions that are predicted to be readmitted.  $Sensitivity = \frac{TP}{TP + FN}$

```{r}
(514) / (5763+514)
```

Specificity is proportion of patients that are not actually readmitted and are predicted as such.  $Specificity = \frac{TN}{TN + FP}$

```{r}
(61095) / (61095+2601)
```

#### Discrimination

There is generally a trade off between a model's sensitivity (ability to identify the true positives) and specificity (ability to identify the true negatives). The values reported above correspond to one specific cutoff for the predictions. To describe the discriminative ability of the model over different possible cutoffs, we can resort to the receiver operating characteristic (ROC) plot, where sensitivity is plotted against specificity for different cutoff values. The area under the ROC curve (AUC) is a popular indicator of how well the model performs with regards to discrimination. 

```{r}
roc <- roc(data$readmitted, pred,
            # arguments for ci
            ci=TRUE, plot = TRUE, auc = TRUE)
roc
```

#### Calibration

To examine how well the predictions match with the observed data, we consider the calibration plot of the observed frequencies versus the predicted probabilities. Ideally, the plot should be a straight line with an intercept of 0 and a slope of 1 (as shown by the red line). 

```{r}
cal = val.prob(pred, ifelse(data$readmitted == "NO", 0,1), logistic.cal = FALSE, lim = c(0,0.4))
cal[c("Intercept", "Slope")]
```

### Validation

Previously, we considered measures of performance using the whole dataset, and predictions of the same observations that were used to build the model. For a more realistic assessment of the model's performance, the model should be validated, and there are a couple of options: split-sample validation and K-fold cross-validation (CV). 

#### Split-sample

We can divide the data into two parts: the training set (80%) and the validation set (20%). This is split smaple validation. 
```{r}
set.seed(123)
indices = sample(1:nrow(data), size = round(nrow(data)/5))
data_val = data[indices, ]
data_train = data[-indices, ]
```


Pseudo $R^2$ with split-sample:
```{r}
fitnull_split = glm(readmitted ~ 1, family = "binomial", data = data_train)
prednull_split <- predict(fitnull_split, data_val, type = "response")
brierScore_null <- mean((prednull_split - ifelse(data_val$readmitted == "NO", 0 , 1))^2)

fit_split = glm(readmitted ~ discharge + race + source + medical_specialty + time_in_hospital + age + diag_1 + A1Cresult  +  diag_1 * discharge + race * discharge + medical_specialty*discharge + discharge*time_in_hospital + time_in_hospital*medical_specialty + age * medical_specialty + time_in_hospital*diag_1 + A1Cresult* diag_1, family = "binomial", data = data_train)
pred_split <- predict(fit_split, data_val, type='response')
brierScore <- mean((pred_split - ifelse(data_val$readmitted == "NO", 0 , 1))^2)

print(c(brierScore, brierScore_null))
```

Nagelkerke's $R^2$ with split-sample:
```{r}
fit_rms = lrm(readmitted ~ discharge + race + source + medical_specialty + time_in_hospital + age + diag_1 + A1Cresult  +  diag_1 * discharge + race * discharge + medical_specialty*discharge + discharge*time_in_hospital + time_in_hospital*medical_specialty + age * medical_specialty + time_in_hospital*diag_1 + A1Cresult* diag_1, data = data_train, x = TRUE, y = TRUE)
fit_rms$stats["R2"]
```

ROC
```{r}
roc_split <- roc(data_val$readmitted, pred_split,
            # arguments for ci
            ci=TRUE, plot = TRUE, auc = TRUE)
roc_split
```

Calibration plot
```{r}
cal_split = val.prob(pred_split, ifelse(data_val$readmitted == "NO", 0,1), logistic.cal = FALSE, lim = c(0,0.4))
cal_split[c("Intercept", "Slope")]
```

#### Cross-validation

Set up 10-fold cross-validation:
```{r, echo=FALSE}
trCntl <- trainControl(method = "CV",number = 10, classProbs = TRUE, savePredictions = TRUE)

fit_CV <- train(readmitted ~ discharge + race + source + medical_specialty + time_in_hospital + age + diag_1 + A1Cresult  +  diag_1 * discharge + race * discharge + medical_specialty*discharge + discharge*time_in_hospital + time_in_hospital*medical_specialty + age * medical_specialty + time_in_hospital*diag_1 + A1Cresult* diag_1, 
                data = data_train, trControl = trCntl, method = "glm", family = "binomial")
```

ROC
```{r}
roc_CV <- roc(fit_CV$pred$obs, fit_CV$pred$YES,
            # arguments for ci
            ci=TRUE, plot = TRUE, auc = TRUE)
roc_CV
```

```{r}
cal_CV = val.prob(fit_CV$pred$YES, ifelse(fit_CV$pred$obs == "NO", 0,1), logistic.cal = FALSE, lim = c(0,0.4))
cal_CV[c("Intercept", "Slope")]
```

The following table summarizes the predictive performance (area under the ROC, intercept and slope of the calibration plot) without and with internal validation. When the full dataset was used, the performance tends to be overestimated. 10-fold CV was superior to the split-sample approach (equivalent to 2-fold CV).


| Type       | AUC           | Intercept | Slope |
|-----------:|:-------------:|:---------:|:-----:|
|Full dataset| 0.6189        | 0         | 1     |
|Split-sample| 0.5933        | -0.592    | 0.753 |
|10-fold CV  | 0.6105        | -0.306    | 0.863 |


### Decision Trees
In addition to regression methods, the data can be explored with decision trees. 

The following metrics are based on a single tree:

```{r}
tree_rpart = rpart(readmitted ~ discharge + race + source + medical_specialty + time_in_hospital + age + diag_1 + A1Cresult, data = data_train, minsplit = 200, cp=-1)
pred_tree = predict(tree_rpart, newdata = data_val)

roc_tree <- roc(data_val$readmitted, pred_tree[, 2],
            # arguments for ci
            ci=TRUE, plot = TRUE, auc = TRUE)
roc_tree

cal_tree = val.prob(pred_tree[,2], ifelse(data_val$readmitted == "NO", 0,1), logistic.cal = FALSE, lim = c(0,0.4))
cal_tree[c("Intercept", "Slope")]
```


Variable importance: discharge, time in hospital and diagnosis are the three most important variables with classification tree, although discharge was not statistically significant in the logistic regression model.
```{r}
tree_rpart$variable.importance
```


Bagging

```{r}
set.seed(123)
tree_bagg <- train(readmitted ~ discharge + race + source + medical_specialty + time_in_hospital + age + diag_1 + A1Cresult, data = data, 
                 method = "bag",
                 trControl = trCntl, bagControl = bagControl(fit = ldaBag$fit, predict = ldaBag$pred, aggregate = ldaBag$aggregate))

roc_bagg <- roc(tree_bagg$pred$obs, tree_bagg$pred$YES,
            # arguments for ci
            ci=TRUE, plot = TRUE, auc = TRUE)
roc_bagg

cal_bagg = val.prob(tree_bagg$pred$YES, ifelse(tree_bagg$pred$obs == "NO", 0,1), logistic.cal = FALSE, lim = c(0,0.4))
cal_bagg[c("Intercept", "Slope")]
```

Random Forest
```{r}

# convert from data.frame to a sparse matrix
temp <- data.table(data[ ,c("discharge","race", "source", "medical_specialty", "time_in_hospital", "age", "diag_1", "A1Cresult")])  # convert x to a data.table
data_sparse <- sparsify(temp)
data_dmat <- xgb.DMatrix(data = data_sparse, label = ifelse(data$readmitted == "NO", 0, 1))

# set parameters for xgboost
params = list(colsample_bynode = floor(sqrt(8))/8,
  eta= 1,
  max_depth = 100,
  subsample = 1,
  num_parallel_tree = 200,
  objective='binary:logistic',
  reg_lambda=0.01,
  min_child_weight=0.01
)

# xgboost for faster random forest
set.seed(123)
tree_rf = xgb.cv(params = params, nfold = 10, data = data_dmat, nrounds = 1, prediction = TRUE)

roc_rf <- roc(data$readmitted, tree_rf$pred,
            # arguments for ci
            ci=TRUE, plot = TRUE, auc = TRUE)
roc_rf

cal_rf = val.prob(tree_rf$pred, ifelse(data$readmitted == "NO", 0,1), logistic.cal = FALSE, lim = c(0,0.4))
cal_rf[c("Intercept", "Slope")]
```

Boosting
```{r}
set.seed(123)
tree_boost <- train(readmitted ~ discharge + race + source + medical_specialty + time_in_hospital + age + diag_1 + A1Cresult, data = data,
                 method = "gbm",
                 trControl = trCntl,
                 verbose = FALSE)

roc_boost <- roc(tree_boost$pred$obs, tree_boost$pred$YES,
            # arguments for ci
            ci=TRUE, plot = TRUE, auc = TRUE)
roc_boost

cal_boost = val.prob(tree_boost$pred$YES, ifelse(tree_boost$pred$obs == "NO", 0,1), logistic.cal = FALSE, lim = c(0,0.4))
cal_boost[c("Intercept", "Slope")]
```

The following table compares logistic regression to different tree-based methods with 10-fold CV. Bagging and boosting but not random forest had similar performance compared to logistic regression. 

| Type              | AUC           | Intercept | Slope |
|------------------:|:-------------:|:---------:|:-----:|
|Logistic regression| 0.611         | -0.306    | 0.863 |
|Bagging            | 0.606         | -0.175    | 0.934 |
|Random Forest      | 0.576         | -1.271    | 0.648 |
|Boosting           | 0.607         |  0.053    | 1.023 |




[1] Beata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, John N. Clore, "Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records", BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014. https://doi.org/10.1155/2014/781670