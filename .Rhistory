data.temp = data.list[[j]]
### additional condition for random forest
if(!is.null(nfeat)) subfeat = sample(feat, nfeat, replace = FALSE) else subfeat = feat
# For each feature of interest, determine the optimal split
for (i in 1:length(subfeat)){
data_sub = data.frame(var = data.temp[, feat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if(is.factor(data_sub$var)) {
if( length(levels(data_sub$var)) > 2 ){
# if more than 2 levels find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = sapply(varcomb, function(varcomb_i){min(length(data_sub$resp[data_sub$var %in% varcomb_i]), length(data_sub$resp[!(data_sub$var %in% varcomb_i)]))})
for(ii in 1:length(varcomb)) {if(count_min[ii] < round(leafsize)) sse[ii] = NA}
# clean up:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]}
} else {
# if only two levels
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = min(sapply(data.split, nrow))
if( count_min < leafsize) error[i] = NA
}
# calculating sse for continuous feature:
} else {
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 1:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
# checking size of children nodes; if less than specified, the split is not considered
count_min = min(length(data_sub$resp[data_sub$var < splits_sort[k]]), length(data_sub$resp[data_sub$var >= splits_sort[k]]))
if(count_min < round(leafsize)) sse[k] = NA
}
# clean up for when none of the splits is valid:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]}
}
}
if(all(is.na(error))){
# if none of the splits is good, set the current node to 'leaf'
output$status[j] = "leaf"
} else {
# otherwise proceed with the split and choose the feature leading to the lowest sse
splitvar = feat[which.min(error)]
feat_list[[output$iter[j] + 1]] = subfeat # to record variables considered for each split
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = unique(data.temp[[splitvar]])[!(unique(data.temp[[splitvar]]) %in% yeslevels)]
children = list()
children[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
children[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else children = split(data.temp, data.temp[ , splitvar])
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
children = list()
children[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
children[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
# - less than 3 observations
# - all observations have the same label
status = sapply(children, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "in", paste(nolevels, collapse = ",")), paste(splitvar, "in", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(children), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(children, nrow), "split rule" = splitrule, iter = output$iter[j] + 1, row.names = NULL, mean = sapply(children, function(x){mean(x[,resp])}))
# attach new outputs to existing dataframes
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(children) = NULL; data.list = c(data.list[1:j], children, data.list[-c(1:j)])
}
}
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
return(list(output = output, feat_list = feat_list))
}
regtree(data = rhcdata, resp = "Y", min.obs = 200, nfeat = 7)
res$output
res = regtree(data = rhcdata, resp = "Y", min.obs = 200, nfeat = 7)
res$output
res = regtree(data = rhcdata, resp = "Y", min.obs = 200, nfeat = 7)
res$output
feat
res$feat_list
regtree <- function(data, resp, min.obs, feat = NULL, nfeat = NULL){
# min.obs sets the minimum size for parent nodes
# feat is the set of predictors
if(is.null(feat)) feat = names(data)[names(data)!=resp] # if undefined, set feat to all covariates in the data
leafsize = min.obs/3 # set minimum size for leaves or terminal nodes
data.list = split_val = feat_list = list(); error = c() # empty objects
data.list[[1]] = data # set root of tree
# data.frame to store output:
output = data.frame(status = "split", count = nrow(data), "split rule" = "root", iter = 0, mean = mean(data[, resp]), stringsAsFactors = FALSE)
stopsplit = FALSE # initialization for while loop
while(!stopsplit) {
# list of splits to be done:
split.queue = which(output$status == "split")
for (j in split.queue[1]) {
# load data corresponding to current node
data.temp = data.list[[j]]
### additional condition for random forest
if(!is.null(nfeat)) subfeat = sample(feat, nfeat, replace = FALSE) else subfeat = feat
# For each feature of interest, determine the optimal split
for (i in 1:length(subfeat)){
data_sub = data.frame(var = data.temp[, subfeat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if(is.factor(data_sub$var)) {
if( length(levels(data_sub$var)) > 2 ){
# if more than 2 levels find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = sapply(varcomb, function(varcomb_i){min(length(data_sub$resp[data_sub$var %in% varcomb_i]), length(data_sub$resp[!(data_sub$var %in% varcomb_i)]))})
for(ii in 1:length(varcomb)) {if(count_min[ii] < round(leafsize)) sse[ii] = NA}
# clean up:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]}
} else {
# if only two levels
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = min(sapply(data.split, nrow))
if( count_min < leafsize) error[i] = NA
}
# calculating sse for continuous feature:
} else {
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 1:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
# checking size of children nodes; if less than specified, the split is not considered
count_min = min(length(data_sub$resp[data_sub$var < splits_sort[k]]), length(data_sub$resp[data_sub$var >= splits_sort[k]]))
if(count_min < round(leafsize)) sse[k] = NA
}
# clean up for when none of the splits is valid:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]}
}
}
if(all(is.na(error))){
# if none of the splits is good, set the current node to 'leaf'
output$status[j] = "leaf"
} else {
# otherwise proceed with the split and choose the feature leading to the lowest sse
splitvar = subfeat[which.min(error)]
feat_list[[output$iter[j] + 1]] = subfeat # to record variables considered for each split
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = unique(data.temp[[splitvar]])[!(unique(data.temp[[splitvar]]) %in% yeslevels)]
children = list()
children[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
children[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else children = split(data.temp, data.temp[ , splitvar])
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
children = list()
children[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
children[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
# - less than 3 observations
# - all observations have the same label
status = sapply(children, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "in", paste(nolevels, collapse = ",")), paste(splitvar, "in", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(children), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(children, nrow), "split rule" = splitrule, iter = output$iter[j] + 1, row.names = NULL, mean = sapply(children, function(x){mean(x[,resp])}))
# attach new outputs to existing dataframes
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(children) = NULL; data.list = c(data.list[1:j], children, data.list[-c(1:j)])
}
}
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
return(list(output = output, feat_list = feat_list))
}
res = regtree(data = rhcdata, resp = "Y", min.obs = 200, nfeat = 7)
res$output
res$feat_list
regtree <- function(data, resp, min.obs, feat = NULL, nfeat = NULL){
# min.obs sets the minimum size for parent nodes
# feat is the set of predictors
if(is.null(feat)) feat = names(data)[names(data)!=resp] # if undefined, set feat to all covariates in the data
leafsize = min.obs/3 # set minimum size for leaves or terminal nodes
data.list = split_val = feat_list = list(); error = c() # empty objects
data.list[[1]] = data # set root of tree
# data.frame to store output:
output = data.frame(status = "split", count = nrow(data), "split rule" = "root", iter = 0, mean = mean(data[, resp]), stringsAsFactors = FALSE)
stopsplit = FALSE; iter = 1 # initialization for while loop
while(!stopsplit) {
# list of splits to be done:
split.queue = which(output$status == "split")
for (j in split.queue[1]) {
# load data corresponding to current node
data.temp = data.list[[j]]
### additional condition for random forest
if(!is.null(nfeat)) subfeat = sample(feat, nfeat, replace = FALSE) else subfeat = feat
# For each feature of interest, determine the optimal split
for (i in 1:length(subfeat)){
data_sub = data.frame(var = data.temp[, subfeat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if(is.factor(data_sub$var)) {
if( length(levels(data_sub$var)) > 2 ){
# if more than 2 levels find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = sapply(varcomb, function(varcomb_i){min(length(data_sub$resp[data_sub$var %in% varcomb_i]), length(data_sub$resp[!(data_sub$var %in% varcomb_i)]))})
for(ii in 1:length(varcomb)) {if(count_min[ii] < round(leafsize)) sse[ii] = NA}
# clean up:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]}
} else {
# if only two levels
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = min(sapply(data.split, nrow))
if( count_min < leafsize) error[i] = NA
}
# calculating sse for continuous feature:
} else {
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 1:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
# checking size of children nodes; if less than specified, the split is not considered
count_min = min(length(data_sub$resp[data_sub$var < splits_sort[k]]), length(data_sub$resp[data_sub$var >= splits_sort[k]]))
if(count_min < round(leafsize)) sse[k] = NA
}
# clean up for when none of the splits is valid:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]}
}
}
if(all(is.na(error))){
# if none of the splits is good, set the current node to 'leaf'
output$status[j] = "leaf"
} else {
# otherwise proceed with the split and choose the feature leading to the lowest sse
splitvar = subfeat[which.min(error)]
feat_list[[iter]] = subfeat # to record variables considered for each split
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = unique(data.temp[[splitvar]])[!(unique(data.temp[[splitvar]]) %in% yeslevels)]
children = list()
children[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
children[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else children = split(data.temp, data.temp[ , splitvar])
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
children = list()
children[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
children[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
# - less than 3 observations
# - all observations have the same label
status = sapply(children, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "in", paste(nolevels, collapse = ",")), paste(splitvar, "in", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(children), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(children, nrow), "split rule" = splitrule, depth = output$iter[j] + 1, row.names = NULL, mean = sapply(children, function(x){mean(x[,resp])}))
# attach new outputs to existing dataframes
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(children) = NULL; data.list = c(data.list[1:j], children, data.list[-c(1:j)])
iter = iter+1
}
}
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
return(list(output = output, feat_list = feat_list))
}
res = regtree(data = rhcdata, resp = "Y", min.obs = 200, nfeat = 7)
res$output
res$feat_list
iter
regtree <- function(data, resp, min.obs, feat = NULL, nfeat = NULL){
# min.obs sets the minimum size for parent nodes
# feat is the set of predictors
if(is.null(feat)) feat = names(data)[names(data)!=resp] # if undefined, set feat to all covariates in the data
leafsize = min.obs/3 # set minimum size for leaves or terminal nodes
data.list = split_val = feat_list = list(); error = c() # empty objects
data.list[[1]] = data # set root of tree
# data.frame to store output:
output = data.frame(status = "split", count = nrow(data), "split rule" = "root", depth = 0, mean = mean(data[, resp]), stringsAsFactors = FALSE)
stopsplit = FALSE; iter = 1 # initialization for while loop
while(!stopsplit) {
# list of splits to be done:
split.queue = which(output$status == "split")
for (j in split.queue[1]) {
# load data corresponding to current node
data.temp = data.list[[j]]
### additional condition for random forest
if(!is.null(nfeat)) subfeat = sample(feat, nfeat, replace = FALSE) else subfeat = feat
# For each feature of interest, determine the optimal split
for (i in 1:length(subfeat)){
data_sub = data.frame(var = data.temp[, subfeat[i]], resp = data.temp[, resp])
# calculating sse for categorical feature:
if(is.factor(data_sub$var)) {
if( length(levels(data_sub$var)) > 2 ){
# if more than 2 levels find all possible binary splits
kk = 1
varcomb = list()
for (ii in 1:(length(levels(data_sub$var))-1)) {
comb = combn(length(levels(data_sub$var)), ii)
for (jj in 1:ncol(comb)){
varcomb[[kk]] = levels(data_sub$var)[comb[, jj]]
kk = kk +1
}
}
# calculate sse for all possible splits
sse = sapply(varcomb, function(varcomb_i){
sum((data_sub$resp[data_sub$var %in% varcomb_i] - mean(data_sub$resp[data_sub$var %in% varcomb_i]))^2) + sum((data_sub$resp[!(data_sub$var %in% varcomb_i)] - mean(data_sub$resp[!(data_sub$var %in% varcomb_i)]))^2) })
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = sapply(varcomb, function(varcomb_i){min(length(data_sub$resp[data_sub$var %in% varcomb_i]), length(data_sub$resp[!(data_sub$var %in% varcomb_i)]))})
for(ii in 1:length(varcomb)) {if(count_min[ii] < round(leafsize)) sse[ii] = NA}
# clean up:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = varcomb[[which.min(sse)]]}
} else {
# if only two levels
data.split = split(data_sub, data_sub$var)
error[i] = sum(sapply(data.split, function(x){
sum( (x$resp - mean(x$resp)) ^ 2 )
}))
# checking size of children nodes; if less than specified by 'leafsize', the split is not considered
count_min = min(sapply(data.split, nrow))
if( count_min < leafsize) error[i] = NA
}
# calculating sse for continuous feature:
} else {
splits_sort = sort(unique(data_sub$var)) # all possible splits
sse <- c()
# calculating sse for all possible splits
for( k in 1:length(splits_sort)){
sse[k] = sum( (data_sub$resp[data_sub$var < splits_sort[k]] - mean(data_sub$resp[data_sub$var < splits_sort[k]]) )^2 ) + sum( (data_sub$resp[data_sub$var >= splits_sort[k]] - mean(data_sub$resp[data_sub$var >= splits_sort[k]]) )^2 )
# checking size of children nodes; if less than specified, the split is not considered
count_min = min(length(data_sub$resp[data_sub$var < splits_sort[k]]), length(data_sub$resp[data_sub$var >= splits_sort[k]]))
if(count_min < round(leafsize)) sse[k] = NA
}
# clean up for when none of the splits is valid:
if(all(is.na(sse))) {error[i] = NA; split_val[[i]] = NA} else { error[i] = min(sse, na.rm = TRUE); split_val[[i]] = splits_sort[which.min(sse)]}
}
}
if(all(is.na(error))){
# if none of the splits is good, set the current node to 'leaf'
output$status[j] = "leaf"
} else {
# otherwise proceed with the split and choose the feature leading to the lowest sse
splitvar = subfeat[which.min(error)]
feat_list[[iter]] = subfeat # to record variables considered for each split
# creating children nodes:
if( is.factor(data.temp[[splitvar]])) {
# for categorical feature:
if( length(levels(data.temp[[splitvar]])) > 2 ){
yeslevels = split_val[[which.min(error)]]
nolevels = unique(data.temp[[splitvar]])[!(unique(data.temp[[splitvar]]) %in% yeslevels)]
children = list()
children[[1]] = data.temp[data.temp[[splitvar]] %in% nolevels, ]
children[[2]] = data.temp[data.temp[[splitvar]] %in% yeslevels, ]
} else children = split(data.temp, data.temp[ , splitvar])
} else {
# for continuous feature:
value = split_val[[which.min(error)]]
index = which(sort(unique(data.temp[[splitvar]])) == value)
# taking the middle point of unique values as the splitting point to be consistent with 'rpart':
value = (sort(unique(data.temp[[splitvar]]))[index] + sort(unique(data.temp[[splitvar]]))[index-1])/2
children = list()
children[[1]] = data.temp[which(data.temp[[splitvar]] <= value), ]
children[[2]] = data.temp[which(data.temp[[splitvar]] > value), ]
}
# Stopping criteria:
# - less than 3 observations
# - all observations have the same label
status = sapply(children, function(x){
if (ncol(x) > 2) {
if (nrow(x) < min.obs | nrow( unique(x[, -which(names(x) %in% resp)]) ) == 1) status = "leaf" else status = "split"
} else status = "leaf"
status
})
# change current status from 'split' to 'parent' so it won't be split further:
output$status[j] = "parent"
# record how the split was done:
if( is.factor(data.temp[[splitvar]]) ) {
if( length(levels(data.temp[[splitvar]])) > 2 ){
splitrule = c(paste(splitvar, "in", paste(nolevels, collapse = ",")), paste(splitvar, "in", paste(yeslevels, collapse = ",")) )
} else splitrule = sapply(names(children), function(x){paste(splitvar, "=" , x)})
} else {
splitrule = c(paste(splitvar, "<=", value),paste(splitvar, ">", value) )
}
# creating outputs
temp.output = data.frame(status = status, count = sapply(children, nrow), "split rule" = splitrule, depth = output$depth[j] + 1, row.names = NULL, mean = sapply(children, function(x){mean(x[,resp])}))
# attach new outputs to existing dataframes
output = rbind(output[1:j,], temp.output, output[-c(1:j), ])
names(children) = NULL; data.list = c(data.list[1:j], children, data.list[-c(1:j)])
iter = iter+1
}
}
# check if there are remaining splits to be done:
if(all(output$status != "split")) stopsplit = TRUE
}
return(list(output = output, feat_list = feat_list))
}
res = regtree(data = rhcdata, resp = "Y", min.obs = 200, nfeat = 7)
res$output
res$feat_list
res = regtree(data = rhcdata, resp = "Y", min.obs = 200, nfeat = 7)
res$output
res$feat_list
set.seed(123)
res = regtree(data = rhcdata, resp = "Y", min.obs = 200, nfeat = 7)
res$output
res$feat_list
